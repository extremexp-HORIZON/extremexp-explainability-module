{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from helpers.logger import LoggerHelper, logging\n",
    "from helpers.config import ConfigHelper\n",
    "from helpers import config\n",
    "from helpers import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from classes import preprocessing_functions\n",
    "from classes.multiclass_models import NeuralNetwork, ConvolutionalNeuralNetwork, RecurrentNeuralNetwork, LongShortTermMemory\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler,MinMaxScaler\n",
    "from modules.lib_IF import *\n",
    "from modules.lib import *\n",
    "from modules.optimizer import *\n",
    "from xai_client import Client\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "with open(models['Ideko_model']['pdp_ale_surrogate_model'], 'rb') as f:\n",
    "                        surrogate_model = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-15 12:26:06,132 - classes.preprocessing_functions - INFO - read_data(): Read data from path data_subset\n",
      "2024-07-15 12:26:06,140 - classes.preprocessing_functions - INFO - read_data(): 1 variables are read: ['f3']\n",
      "2024-07-15 12:26:27,855 - classes.preprocessing_functions - INFO - read_data(): Number of files read 648\n"
     ]
    }
   ],
   "source": [
    "indicator_list = [\"f3\"]\n",
    "\n",
    "X, Y, Z = preprocessing_functions.read_data('data_subset', indicator_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-15 12:26:27,880 - classes.preprocessing_functions - INFO - add_padding(): Matching the length of the time series adding padding\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X_pad = preprocessing_functions.add_padding(X, indicator_list)\n",
    "\n",
    "Y_encoded = preprocessing_functions.encode_response_variable(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test,z_train,z_test = preprocessing_functions.split_data(X_pad, Y_encoded, Z)\n",
    "\n",
    "n_timestamps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "n_classes = y_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.layers import Masking, Dense, Flatten, Conv1D, MaxPooling1D, SimpleRNN, LSTM\n",
    "from keras import Input\n",
    "\n",
    "def create_model(n_timestamps, n_features, activation_function='relu', units=(50, 50,50), n_classes=2):\n",
    "    model = Sequential()\n",
    "    # Input layer\n",
    "    model.add(Input(shape=(n_timestamps, n_features)))\n",
    "    # Masking layer\n",
    "    model.add(Masking(mask_value=0))\n",
    "    # Fully connected layers\n",
    "    for unit in units:\n",
    "        model.add(Dense(units=unit, activation=activation_function))\n",
    "    # Flatten layer\n",
    "    model.add(Flatten())\n",
    "    # Output layer\n",
    "    model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020F885FD5A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2024-07-12 19:39:51,394 - tensorflow - WARNING - 5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020F885FD5A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020F885FD5A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2024-07-12 19:39:52,117 - tensorflow - WARNING - 5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020F885FD5A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, \n",
    "                        n_timestamps=n_timestamps, \n",
    "                        n_features=n_features, \n",
    "                        n_classes=n_classes, \n",
    "                        verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'model__units': [[25, 25, 25],[50, 50, 50],[100, 100, 100]],     # Example values\n",
    "    'model__activation_function': ['relu', 'tanh'],       # Example values\n",
    "    'batch_size': (16,32,64) ,                        # Example values\n",
    "    'epochs': (15,30,50),                       # Example values\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "with open('metadata/proxy_data_models/Ideko_nn_grid.pkl', 'wb') as file:\n",
    "    pickle.dump(grid_result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xai_client import Client\n",
    "\n",
    "client = Client()\n",
    "k = client.get_explanations(explanation_type='hyperparameterExplanation',explanation_method='pdp',model='Ideko_model',feature1='batch_size')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExtremeXP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
