{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from helpers.logger import LoggerHelper, logging\n",
    "from helpers.config import ConfigHelper\n",
    "from helpers import config\n",
    "from helpers import logger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from classes import preprocessing_functions\n",
    "from classes.multiclass_models import NeuralNetwork, ConvolutionalNeuralNetwork, RecurrentNeuralNetwork, LongShortTermMemory\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler,MinMaxScaler\n",
    "from modules.lib_IF import *\n",
    "from modules.lib import *\n",
    "from modules.optimizer import *\n",
    "from xai_client import Client\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-23 09:58:18,791 - classes.preprocessing_functions - INFO - read_data(): Read data from path data_subset\n",
      "2024-07-23 09:58:18,794 - classes.preprocessing_functions - INFO - read_data(): 1 variables are read: ['f3']\n",
      "2024-07-23 09:58:39,997 - classes.preprocessing_functions - INFO - read_data(): Number of files read 648\n"
     ]
    }
   ],
   "source": [
    "indicator_list = [\"f3\"]\n",
    "\n",
    "X, Y, Z = preprocessing_functions.read_data('data_subset', indicator_list)\n",
    "#2 not anomalous\n",
    "#0 electrical\n",
    "#1 mechanical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'electrical anomaly'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-23 09:58:56,687 - classes.preprocessing_functions - INFO - add_padding(): Matching the length of the time series adding padding\n",
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X_pad = preprocessing_functions.add_padding(X, indicator_list)\n",
    "\n",
    "Y_encoded = preprocessing_functions.encode_response_variable(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test,z_train,z_test = preprocessing_functions.split_data(X_pad, Y_encoded, Z)\n",
    "\n",
    "n_timestamps = X_train.shape[1]\n",
    "n_features = X_train.shape[2]\n",
    "\n",
    "n_classes = y_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.layers import Masking, Dense, Flatten, Conv1D, MaxPooling1D, SimpleRNN, LSTM\n",
    "from keras import Input\n",
    "\n",
    "# def create_model(n_timestamps, n_features, activation_function='relu', units=(50, 50,50), n_classes=2):\n",
    "#     model = Sequential()\n",
    "#     # Input layer\n",
    "#     model.add(Input(shape=(n_timestamps, n_features)))\n",
    "#     # Masking layer\n",
    "#     model.add(Masking(mask_value=0))\n",
    "#     # Fully connected layers\n",
    "#     for unit in units:\n",
    "#         model.add(Dense(units=unit, activation=activation_function))\n",
    "#     # Flatten layer\n",
    "#     model.add(Flatten())\n",
    "#     # Output layer\n",
    "#     model.add(Dense(n_classes, activation=\"softmax\"))\n",
    "    \n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002A745251990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2024-07-22 12:17:06,171 - tensorflow - WARNING - 5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002A745251990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002A745251990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2024-07-22 12:17:12,728 - tensorflow - WARNING - 5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002A745251990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model, \n",
    "                        n_timestamps=n_timestamps, \n",
    "                        n_features=n_features, \n",
    "                        n_classes=n_classes, \n",
    "                        verbose=0)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'model__units': [[100, 100, 100],[256, 256, 128],[512,512,256,256],[512,512,512]],     # Example values\n",
    "    'model__activation_function': ['relu'],       # Example values\n",
    "    'batch_size': [64] ,                        # Example values\n",
    "    'epochs': [50],                       # Example values\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2)\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill as pickle\n",
    "# with open('metadata/proxy_data_models/Ideko_nn_grid.pkl', 'wb') as file:\n",
    "#     pickle.dump(grid_result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "with open('metadata/proxy_data_models/Ideko_nn_grid.pkl', 'rb') as f:\n",
    "                            original_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__units': [[25, 25, 25], [50, 50, 50], [100, 100, 100]],\n",
       " 'model__activation_function': ['relu', 'tanh'],\n",
       " 'batch_size': (16, 32, 64),\n",
       " 'epochs': (15, 30, 50)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model.param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xai_client import Client\n",
    "\n",
    "client = Client()\n",
    "k = client.get_explanations(explanation_type='hyperparameterExplanation',explanation_method='ale',model='Ideko_model',feature1='batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import xai_service_pb2\n",
    "import xai_service_pb2_grpc\n",
    "with grpc.insecure_channel('localhost:50051') as channel:\n",
    "    stub = xai_service_pb2_grpc.ExplanationsStub(channel)\n",
    "    k = stub.GetExplanation(xai_service_pb2.ExplanationsRequest(explanation_type='hyperparameterExplanation',explanation_method='counterfactuals',model='Ideko_model',model_id=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(mdl.predict(X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(columns=['Predictions','Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['Predictions'] = list(preds)\n",
    "predictions['Labels'] = list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = pd.DataFrame(columns = ['hyperparameters','BinaryLabel'])\n",
    "for i,params_dict in enumerate(original_model.cv_results_['params']):\n",
    "    # mdl = deepcopy(original_model.estimator)\n",
    "    # mdl.set_params(**params_dict)\n",
    "    # mdl.fit(X_train, y_train)\n",
    "    # prediction = np.argmax(mdl.predict([X_test[3]]),axis=1)\n",
    "    proxy = proxy.append({'hyperparameters' : params_dict},ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy['BinaryLabel'] = 0\n",
    "\n",
    "# Set the first 6 values to 2\n",
    "proxy.loc[:5, 'BinaryLabel'] = 2\n",
    "\n",
    "# Set the next 4 values to 1\n",
    "proxy.loc[6:9, 'BinaryLabel'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(proxy['hyperparameters'].iloc[0].keys())\n",
    "\n",
    "# Create new columns for each key\n",
    "for key in keys:\n",
    "    proxy[key] = proxy['hyperparameters'].apply(lambda x: x.get(key, None))\n",
    "\n",
    "# Drop the original \"Hyperparameters\" column\n",
    "proxy_dataset = proxy.drop(columns=['hyperparameters'])\n",
    "proxy_dataset['BinaryLabel'] = proxy_dataset['BinaryLabel'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = transform_grid(original_model.param_grid)\n",
    "param_space, name = dimensions_aslists(param_grid)\n",
    "space = Space(param_space)\n",
    "\n",
    "plot_dims = []\n",
    "for row in range(space.n_dims):\n",
    "    if space.dimensions[row].is_constant:\n",
    "        continue\n",
    "    plot_dims.append((row, space.dimensions[row]))\n",
    "iscat = [isinstance(dim[1], Categorical) for dim in plot_dims]\n",
    "categorical = [name[i] for i,value in enumerate(iscat) if value == True]\n",
    "proxy_dataset[categorical] = proxy_dataset[categorical].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transf = ColumnTransformer(transformers=[(\"cat\", OneHotEncoder(), categorical)], remainder=\"passthrough\")\n",
    "\n",
    "proxy_model = Pipeline([\n",
    "    (\"one-hot\", cat_transf),\n",
    "    (\"svm\", SVC(kernel='linear', C=2.0 ,probability=True))\n",
    "])\n",
    "\n",
    "proxy_model = proxy_model.fit(proxy_dataset.drop(columns='BinaryLabel'), proxy_dataset['BinaryLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = json.load(open(\"metadata/models.json\"))\n",
    "import joblib\n",
    "with open(models['Ideko_model']['cfs_surrogate_model'], 'rb') as f:\n",
    "    surrogate_model = joblib.load(f)\n",
    "proxy_dataset = pd.read_csv(models['Ideko_model']['cfs_surrogate_dataset'],index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100, 100, 100]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['model__units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = pd.DataFrame(data = {'model__units': [params['model__units']], 'model__activation_function': params['model__activation_function'], 'batch_size':params['batch_size'],'epochs':params['epochs']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model__units</th>\n",
       "      <th>model__activation_function</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>tanh</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model__units model__activation_function  batch_size  epochs\n",
       "0  [100, 100, 100]                       tanh          16      50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model__activation_function</th>\n",
       "      <th>model__units</th>\n",
       "      <th>BinaryLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  epochs model__activation_function     model__units  BinaryLabel\n",
       "0          16      50                       tanh  [100, 100, 100]            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set (new outcome: 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>model__activation_function</th>\n",
       "      <th>model__units</th>\n",
       "      <th>BinaryLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[25, 25, 25]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>relu</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>tanh</td>\n",
       "      <td>[100, 100, 100]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  epochs model__activation_function     model__units  BinaryLabel\n",
       "0          16      17                       tanh  [100, 100, 100]            2\n",
       "1          16      16                       tanh     [25, 25, 25]            2\n",
       "2          16      17                       relu  [100, 100, 100]            2\n",
       "3          16      18                       tanh  [100, 100, 100]            2\n",
       "4          16      15                       tanh  [100, 100, 100]            2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e1.visualize_as_dataframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExtremeXP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
